{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "♫♫♫ > DUET LIVE STATUS  -  Objects: 24  Requests: 0   Messages: 392  Request Handlers: 1                                \r"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "duet = sy.launch_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import re\n",
    "from typing import Any\n",
    "from typing import List as TypeList\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from original.neural_style import utils\n",
    "\n",
    "from syft import SyModule\n",
    "from syft import SySequential\n",
    "from syft.core.plan.plan_builder import PLAN_BUILDER_VM\n",
    "from syft.core.plan.plan_builder import ROOT_CLIENT\n",
    "# from original.neural_style.vgg import Vgg16\n",
    "# from original.neural_style.transformer_net import TransformerNet # redefined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handler with no tags accepts everything. Better handlers coming soon.\n",
    "duet.requests.add_handler(action=\"accept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"image_size\":None,\n",
    "        \"dataset\":None,\n",
    "        \"batch_size\":4,\n",
    "        \"cuda\":False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(TransformerNet, self).__init__(torch_ref=torch_ref)\n",
    "        # Initial convolution layers\n",
    "        self.conv1 = ConvLayer(self.torch_ref, 3, 32, kernel_size=9, stride=1)\n",
    "        self.in1 = self.torch_ref.nn.InstanceNorm2d(32, affine=True)\n",
    "        self.conv2 = ConvLayer(self.torch_ref, 32, 64, kernel_size=3, stride=2)\n",
    "        self.in2 = self.torch_ref.nn.InstanceNorm2d(64, affine=True)\n",
    "        self.conv3 = ConvLayer(self.torch_ref, 64, 128, kernel_size=3, stride=2)\n",
    "        self.in3 = self.torch_ref.nn.InstanceNorm2d(128, affine=True)\n",
    "        # Residual layers\n",
    "        self.res1 = ResidualBlock(self.torch_ref, 128)\n",
    "        self.res2 = ResidualBlock(self.torch_ref, 128)\n",
    "        self.res3 = ResidualBlock(self.torch_ref, 128)\n",
    "        self.res4 = ResidualBlock(self.torch_ref, 128)\n",
    "        self.res5 = ResidualBlock(self.torch_ref, 128)\n",
    "        # Upsampling Layers\n",
    "        self.deconv1 = UpsampleConvLayer(self.torch_ref, 128, 64, kernel_size=3, stride=1, upsample=2)\n",
    "        self.in4 = self.torch_ref.nn.InstanceNorm2d(64, affine=True)\n",
    "        self.deconv2 = UpsampleConvLayer(self.torch_ref, 64, 32, kernel_size=3, stride=1, upsample=2)\n",
    "        self.in5 = self.torch_ref.nn.InstanceNorm2d(32, affine=True)\n",
    "        self.deconv3 = ConvLayer(self.torch_ref, 32, 3, kernel_size=9, stride=1)\n",
    "        # Non-linearities\n",
    "        self.relu = self.torch_ref.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.relu(self.in1(self.conv1(x)))\n",
    "        y = self.relu(self.in2(self.conv2(y)))\n",
    "        y = self.relu(self.in3(self.conv3(y)))\n",
    "        y = self.res1(y)\n",
    "        y = self.res2(y)\n",
    "        y = self.res3(y)\n",
    "        y = self.res4(y)\n",
    "        y = self.res5(y)\n",
    "        y = self.relu(self.in4(self.deconv1(y)))\n",
    "        y = self.relu(self.in5(self.deconv2(y)))\n",
    "        y = self.deconv3(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ConvLayer(sy.Module):\n",
    "    def __init__(self, torch_ref, in_channels, out_channels, kernel_size, stride):\n",
    "        super(ConvLayer, self).__init__(torch_ref=torch_ref)\n",
    "        reflection_padding = kernel_size // 2\n",
    "        self.reflection_pad = self.torch_ref.nn.ReflectionPad2d(reflection_padding)\n",
    "        self.conv2d = self.torch_ref.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.reflection_pad(x)\n",
    "        out = self.conv2d(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlock(sy.Module):\n",
    "    \"\"\"ResidualBlock\n",
    "    introduced in: https://arxiv.org/abs/1512.03385\n",
    "    recommended architecture: http://torch.ch/blog/2016/02/04/resnets.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, torch_ref, channels):\n",
    "        super(ResidualBlock, self).__init__(torch_ref=torch_ref)\n",
    "        self.conv1 = ConvLayer(self.torch_ref, channels, channels, kernel_size=3, stride=1)\n",
    "        self.in1 = self.torch_ref.nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.conv2 = ConvLayer(self.torch_ref, channels, channels, kernel_size=3, stride=1)\n",
    "        self.in2 = self.torch_ref.nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.relu = self.torch_ref.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.in1(self.conv1(x)))\n",
    "        out = self.in2(self.conv2(out))\n",
    "        out = out + residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class UpsampleConvLayer(sy.Module):\n",
    "    \"\"\"UpsampleConvLayer\n",
    "    Upsamples the input and then does a convolution. This method gives better results\n",
    "    compared to ConvTranspose2d.\n",
    "    ref: http://distill.pub/2016/deconv-checkerboard/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, torch_ref, in_channels, out_channels, kernel_size, stride, upsample=None):\n",
    "        super(UpsampleConvLayer, self).__init__(torch_ref=torch_ref)\n",
    "        self.upsample = upsample\n",
    "        reflection_padding = kernel_size // 2\n",
    "        self.reflection_pad = self.torch_ref.nn.ReflectionPad2d(reflection_padding)\n",
    "        self.conv2d = self.torch_ref.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        if self.upsample:\n",
    "            x_in = self.torch_ref.nn.functional.interpolate(\n",
    "                x_in, mode=\"nearest\", scale_factor=self.upsample\n",
    "            )\n",
    "        out = self.reflection_pad(x_in)\n",
    "        out = self.conv2d(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch = duet.torch\n",
    "remote_python = duet.python\n",
    "remote_torchvision = duet.torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"original/download_saved_models.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerNet(torch_ref=torch)\n",
    "model_params_zeros = sy.lib.python.List(\n",
    "        [torch.nn.Parameter(torch.zeros_like(param)) for param in model.parameters()]\n",
    "    )\n",
    "model_params = sy.lib.python.List(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_remote_model_params(module_ptrs, params_list_ptr):  # type: ignore\n",
    "    param_idx = 0\n",
    "    for module_name, module_ptr in module_ptrs.items():\n",
    "        for param_name, _ in PLAN_BUILDER_VM.store[\n",
    "            module_ptr.id_at_location\n",
    "        ].data.named_parameters():\n",
    "            module_ptr.register_parameter(param_name, params_list_ptr[param_idx])\n",
    "            param_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = utils.load_image(\"original/images/content_images/amber.jpg\")\n",
    "content_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Lambda(lambda x: x.mul(255))]\n",
    ")\n",
    "\n",
    "content_image = content_transform(content_image)\n",
    "content_image = content_image.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = model.send(duet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_remote_model_params(local_model.modules, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = local_model(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from syft.core.plan.plan_builder import make_plan\n",
    "\n",
    "@make_plan\n",
    "def stylize(x=content_image, model_params=model_params_zeros):\n",
    "    local_model = model.send(ROOT_CLIENT, send_parameters=False)\n",
    "    set_remote_model_params(local_model.modules, model_params)\n",
    "    output = local_model(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylize.tag(\"stylize\")\n",
    "stylize.send(duet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run \"original/download_saved_models.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_path = \"saved_models/mosaic.pth\" \n",
    "device = torch.device(\"cuda\" if args[\"cuda\"] else \"cpu\")\n",
    "\n",
    "# TODO\n",
    "# load weights into the model\n",
    "with torch.no_grad():\n",
    "    style_model = TransformerNet(input_size=(1, 3, 1080, 1080))\n",
    "    state_dict = torch.load(model_path)\n",
    "    # remove saved deprecated running_* keys in InstanceNorm from the checkpoint\n",
    "    for k in list(state_dict.keys()):\n",
    "        if re.search(r\"in\\d+\\.running_(mean|var)$\", k):\n",
    "            del state_dict[k]\n",
    "    style_model.load_state_dict(state_dict)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylize_ptr = duet.store[\"stylize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylized_image = stylize_ptr(x=content_image, style_model=dummy_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
